{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import collections\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA = 0.9\n",
    "TEST_EPISODES = 20\n",
    "ENV = \"FrozenLake8x8-v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self, env=ENV):\n",
    "        self.env = gym.make(env)\n",
    "        self.old_obs, _ = self.env.reset()\n",
    "        self.rewards = collections.defaultdict(float)\n",
    "        self.transits = collections.defaultdict(collections.Counter)\n",
    "        self.values = collections.defaultdict(float)\n",
    "\n",
    "    def play_n_random_steps(self, count=1000):\n",
    "        for i in range(count):\n",
    "            action = self.env.action_space.sample()\n",
    "            new_obs, reward, terminated, truncated, info = self.env.step(action)\n",
    "            self.rewards[(self.old_obs, action, new_obs)] = reward\n",
    "            self.transits[(self.old_obs, action)][new_obs] += 1\n",
    "            if (terminated or truncated):\n",
    "                self.old_obs, _ = self.env.reset()\n",
    "            else:\n",
    "                self.old_obs = new_obs\n",
    "\n",
    "    def calc_action_value(self, state, action):\n",
    "        target_counts = self.transits[(state, action)]\n",
    "        total = sum(target_counts.values())\n",
    "        action_value = 0.0\n",
    "        for target_state, count in target_counts.items():\n",
    "            reward = self.rewards[(state, action, target_state)]\n",
    "            val = reward + GAMMA*self.values[(target_state)]\n",
    "            action_value += (count/total)*val\n",
    "        return action_value\n",
    "\n",
    "    def select_action(self, state):\n",
    "        best_action, best_value = None, None\n",
    "        for action in range(self.env.action_space.n):\n",
    "            action_value = self.calc_action_value(state, action)\n",
    "            if best_value is None or best_value<action_value:\n",
    "                best_action = action\n",
    "                best_value = action_value\n",
    "        return best_action\n",
    "    \n",
    "    def play_episode(self, env):\n",
    "        total_reward = 0.0\n",
    "        state, _ = env.reset()\n",
    "        while True:\n",
    "            action = self.select_action(state)\n",
    "            new_state, reward, terminated, truncated, _ = env.step(action)\n",
    "            self.rewards[(state, action, new_state)] = reward\n",
    "            self.transits[(state, action)][new_state] += 1\n",
    "            total_reward += reward\n",
    "            if (terminated or truncated):\n",
    "                break\n",
    "            state = new_state\n",
    "        return total_reward\n",
    "\n",
    "    def value_iteration(self):\n",
    "        for state in range(self.env.observation_space.n):\n",
    "            state_values = [self.calc_action_value(state, action) for action in range(self.env.action_space.n)]\n",
    "            self.values[state] = max(state_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best reward updated: 0.05\n",
      "V(S) = defaultdict(<class 'float'>, {0: 0.0, 8: 0.0, 1: 0.0, 9: 0.0, 2: 0.0, 10: 0.005575117304963663, 3: 0.011911102946954445, 11: 0.028048046587298807, 4: 0.044795040169256006, 12: 0.07658866889381666, 5: 0.09105860569532159, 6: 0.13082626632988031, 14: 0.21657535512604015, 7: 0.15214852197923207, 15: 0.2627352809595015, 19: 0.0, 13: 0.14705221143586447, 21: 0.17688941832175503, 22: 0.3329316540263473, 16: 0.0, 17: 0.003106373164268094, 18: 0.008368951824260515, 20: 0.12129085559554652, 29: 0.0, 23: 0.36716326203698035, 24: 0.0013922923823437505, 25: 0.006731183916981508, 26: 0.020015251553844864, 27: 0.04008345833114755, 28: 0.1271400985997299, 30: 0.535087757223992, 31: 0.5961489786110942, 32: 0.0011482129056359087, 33: 0.003263995926529338, 34: 0.006483392955266139, 35: 0.0, 36: 0.165723129227438, 37: 0.19319232428392125, 38: 0.48157898150159284, 39: 0.81, 40: 0.000516695807536159, 41: 0.0, 42: 0.0, 43: 0.1016883878056726, 44: 0.12994039387816458, 45: 0.17387309185552913, 46: 0.0, 47: 0.9, 48: 0.0003100174845216954, 49: 0.0, 50: 0.0, 51: 0.0, 52: 0.0, 53: 0.0, 54: 0.0, 55: 1.0, 56: 9.405396919138912e-05, 57: 0.0, 58: 0.0, 59: 0.0, 60: 0.0, 61: 0.0, 62: 0.0, 63: 0.0})\n",
      "Best reward updated: 0.3\n",
      "V(S) = defaultdict(<class 'float'>, {0: 0.0, 8: 0.0, 1: 0.0, 9: 0.002835809985008495, 2: 0.005636875116767116, 10: 0.013078353460012791, 3: 0.025864176888737413, 11: 0.04025581122609569, 4: 0.06384938148394588, 12: 0.09105199033905524, 5: 0.11153282452032758, 6: 0.14980194056198692, 14: 0.22948664927660933, 7: 0.16958171665650953, 15: 0.27234183331219836, 19: 0.0, 13: 0.1579073656147536, 21: 0.1872125206447915, 22: 0.34902010886215495, 16: 0.001447340762703306, 17: 0.005587368646978681, 18: 0.01180641605148667, 20: 0.12067607928833926, 29: 0.0, 23: 0.3936997048530688, 24: 0.002808637602952564, 25: 0.007612142631225494, 26: 0.01907515402154634, 27: 0.05646824499878672, 28: 0.11809777398861063, 30: 0.4412129452753939, 31: 0.5791318937471048, 32: 0.002193742283100794, 33: 0.004722622069062087, 34: 0.006201541640575602, 35: 0.0, 36: 0.13982090508962589, 37: 0.18641996597736563, 38: 0.3970916507478545, 39: 0.81, 40: 0.001056937961412739, 41: 0.0, 42: 0.0, 43: 0.05847317724517406, 44: 0.08923233705065997, 45: 0.16777796937962908, 46: 0.0, 47: 0.9, 48: 0.0007271680222041519, 49: 0.0, 50: 0.0, 51: 0.0, 52: 0.0, 53: 0.0, 54: 0.0, 55: 0.9366666666666666, 56: 0.00027672447963137444, 57: 0.0, 58: 0.0, 59: 0.0, 60: 0.0, 61: 0.0, 62: 0.0, 63: 0.0})\n",
      "Best reward updated: 0.4\n",
      "V(S) = defaultdict(<class 'float'>, {0: 0.0, 8: 0.0012718732624466848, 1: 0.0026045037629980347, 9: 0.006628231906362074, 2: 0.013914369892635614, 10: 0.020639328886855483, 3: 0.0392356557164522, 11: 0.049426541825953185, 4: 0.07608072413944332, 12: 0.105625238488531, 5: 0.12677050227167325, 6: 0.16288554484176748, 14: 0.2376377954523497, 7: 0.18798511454590444, 15: 0.27595811494691985, 19: 0.0, 13: 0.1656785071702273, 21: 0.19039162982491292, 22: 0.3260308712552108, 16: 0.0031048774554473953, 17: 0.008145861839801977, 18: 0.014999294227699753, 20: 0.1199239761667582, 29: 0.0, 23: 0.3933827991638803, 24: 0.004058653084137523, 25: 0.008776037028290025, 26: 0.0241944265542241, 27: 0.0540422926184521, 28: 0.1091651214429672, 30: 0.4141948689560717, 31: 0.5156682412481477, 32: 0.0032681803073983376, 33: 0.0053783414214097, 34: 0.007988052755285238, 35: 0.0, 36: 0.12035854678204852, 37: 0.14490338953626292, 38: 0.4645877734316622, 39: 0.6793763320294987, 40: 0.001634293943325186, 41: 0.0, 42: 0.0, 43: 0.04015455167279699, 44: 0.07223089430468048, 45: 0.07824783034958198, 46: 0.0, 47: 0.7532281067237675, 48: 0.001198726772656357, 49: 0.0, 50: 0.0, 51: 0.0, 52: 0.0, 53: 0.0, 54: 0.0, 55: 0.8760900657891979, 56: 0.0005287716590832941, 57: 0.0, 58: 0.0, 59: 0.0, 60: 0.0, 61: 0.0, 62: 0.0, 63: 0.0})\n",
      "Best reward updated: 0.45\n",
      "V(S) = defaultdict(<class 'float'>, {0: 0.006427880392974214, 8: 0.008759424357373131, 1: 0.01815128479770533, 9: 0.020090227834412465, 2: 0.036859366108020354, 10: 0.03610466393944733, 3: 0.06793388325549261, 11: 0.06584394295334481, 4: 0.1078871559088393, 12: 0.12057365763204916, 5: 0.15365560272468656, 6: 0.1793938486917572, 14: 0.22093812767986862, 7: 0.19689510510274083, 15: 0.2495946517892954, 19: 0.0, 13: 0.17220718966355464, 21: 0.17794389847906328, 22: 0.2660728349395425, 16: 0.009314276427392472, 17: 0.01724687585516601, 18: 0.024719417417993238, 20: 0.11208113661616118, 29: 0.0, 23: 0.30188348245323415, 24: 0.00898812817755913, 25: 0.01530199298486324, 26: 0.02353741030345998, 27: 0.029116494298425475, 28: 0.07188792750395069, 30: 0.3047209194350028, 31: 0.3537407356139834, 32: 0.0068432908986394555, 33: 0.009460136436659595, 34: 0.009193988693843492, 35: 0.0, 36: 0.07955765320852223, 37: 0.11693596069979337, 38: 0.27662927804751875, 39: 0.4277550282764814, 40: 0.0035735109927008697, 41: 0.0, 42: 0.0, 43: 0.026959317100389204, 44: 0.0558223870552301, 45: 0.06314541877788842, 46: 0.0, 47: 0.5452234683283281, 48: 0.0028028133800380075, 49: 0.0, 50: 0.0, 51: 0.0, 52: 0.0, 53: 0.0, 54: 0.0, 55: 0.7688647076894111, 56: 0.0015370457396968863, 57: 0.0, 58: 0.0, 59: 0.0, 60: 0.0, 61: 0.0, 62: 0.0, 63: 0.0})\n",
      "Best reward updated: 0.7\n",
      "V(S) = defaultdict(<class 'float'>, {0: 0.009931965091832848, 8: 0.012075349106383929, 1: 0.0232497340386653, 9: 0.02331259994534532, 2: 0.04196404643250235, 10: 0.0393839317955056, 3: 0.07372792634797927, 11: 0.06824583064374605, 4: 0.11264068672363783, 12: 0.11971325983923764, 5: 0.15422163503735853, 6: 0.17811603210536414, 14: 0.2074746360026593, 7: 0.1935859176089577, 15: 0.2284484045261846, 19: 0.0, 13: 0.1704387480470661, 21: 0.1710522501054972, 22: 0.24089841843569404, 16: 0.011872060678381965, 17: 0.019280649372019332, 18: 0.025166825110467257, 20: 0.11211996504378643, 29: 0.0, 23: 0.27024698117904067, 24: 0.010890581092052386, 25: 0.015843744171431678, 26: 0.021488146467907185, 27: 0.03001373806238289, 28: 0.06991369928689194, 30: 0.262566859745566, 31: 0.3118292789899076, 32: 0.008141671544979783, 33: 0.00976740824200839, 34: 0.008790626468389507, 35: 0.0, 36: 0.07280161411257462, 37: 0.10233393468903679, 38: 0.23769764194383752, 39: 0.3798805347729334, 40: 0.004360823623517099, 41: 0.0, 42: 0.0, 43: 0.025120074174853544, 44: 0.05121699072000083, 45: 0.05526032473207987, 46: 0.0, 47: 0.5068625821782708, 48: 0.003457338188121662, 49: 0.0, 50: 0.0, 51: 0.0, 52: 0.0, 53: 0.0, 54: 0.0, 55: 0.7499247631068161, 56: 0.0019659248450356517, 57: 0.0, 58: 0.0, 59: 0.0, 60: 0.0, 61: 0.0, 62: 0.0, 63: 0.0})\n",
      "Best reward updated: 0.9\n",
      "V(S) = defaultdict(<class 'float'>, {0: 0.013460137304304735, 8: 0.015261555342625301, 1: 0.02725219476227999, 9: 0.025619653889215457, 2: 0.04578393850412343, 10: 0.04195513910864924, 3: 0.07791283071060515, 11: 0.0716038029190491, 4: 0.1145783200371849, 12: 0.11852620284388304, 5: 0.15323751707942704, 6: 0.1732790645260751, 14: 0.1920605000268099, 7: 0.18518845710588, 15: 0.2090147069881355, 19: 0.0, 13: 0.16284949229313708, 21: 0.158848052024134, 22: 0.2159561735731314, 16: 0.014175627049037886, 17: 0.02015313090656429, 18: 0.025819880536289017, 20: 0.11088951040107783, 29: 0.0, 23: 0.2401562558912918, 24: 0.012343379535691989, 25: 0.01639776751088007, 26: 0.022040899985840155, 27: 0.02886334178901758, 28: 0.0687970981904973, 30: 0.23063260617662376, 31: 0.2775538844160741, 32: 0.009066870142092984, 33: 0.010135082012829713, 34: 0.009053734870915361, 35: 0.0, 36: 0.06543460037284685, 37: 0.09189833726558098, 38: 0.21072344346454144, 39: 0.34722044432347776, 40: 0.005071144625533286, 41: 0.0, 42: 0.0, 43: 0.027657174988800447, 44: 0.04450563002811815, 45: 0.047262002022298785, 46: 0.0, 47: 0.4847608331813907, 48: 0.00407988823175647, 49: 0.0, 50: 0.0, 51: 0.0, 52: 0.0, 53: 0.0, 54: 0.0, 55: 0.7401924188166016, 56: 0.002410672469310533, 57: 0.0, 58: 0.0, 59: 0.0, 60: 0.0, 61: 0.0, 62: 0.0, 63: 0.0})\n",
      "Best reward updated: 0.95\n",
      "V(S) = defaultdict(<class 'float'>, {0: 0.005962740815933209, 8: 0.005604251551484266, 1: 0.007880565942831992, 9: 0.0070486169153280995, 2: 0.011277494505903827, 10: 0.009919279636815399, 3: 0.01637904972380815, 11: 0.014980445080851659, 4: 0.02327799548274606, 12: 0.023889110198910206, 5: 0.03054864226180908, 6: 0.03720746330339088, 14: 0.046158745451670195, 7: 0.040735547283485385, 15: 0.053730111909289655, 19: 0.0, 13: 0.034059946270748424, 21: 0.036572527648676245, 22: 0.06214119276100831, 16: 0.00465484008006286, 17: 0.0052655018354735, 18: 0.006104231242607093, 20: 0.022317490920765057, 29: 0.0, 23: 0.07832827934210548, 24: 0.003829854483609567, 25: 0.004222990368948677, 26: 0.004926326644203977, 27: 0.005847587794571684, 28: 0.013614269084626417, 30: 0.08306464589059323, 31: 0.11952171245336607, 32: 0.002839333340824505, 33: 0.0027726568835314503, 34: 0.0023130713517180404, 35: 0.0, 36: 0.017971187995355936, 37: 0.03333205554518242, 38: 0.09527697642479367, 39: 0.2009634228893024, 40: 0.0016970331170466921, 41: 0.0, 42: 0.0, 43: 0.007994797813609346, 44: 0.012475271707995273, 45: 0.014993605206184537, 46: 0.0, 47: 0.3495707407098778, 48: 0.0010971019430717462, 49: 0.0, 50: 0.000310168314122236, 51: 0.0002791514827100124, 52: 0.0, 53: 0.0, 54: 0.0, 55: 0.624473742765353, 56: 0.0008405225077043484, 57: 0.0007564702569339136, 58: 0.0006808232312405223, 59: 0.0, 60: 0.0, 61: 0.0, 62: 0.0, 63: 0.0})\n",
      "WON!\n",
      "Solved in 118 iterations\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    test_env = gym.make(ENV, render_mode='human')\n",
    "    agent = Agent()\n",
    "    iter_no = 0\n",
    "    best_reward = 0.0\n",
    "    while True:\n",
    "        iter_no += 1\n",
    "        agent.play_n_random_steps(100)\n",
    "        agent.value_iteration()\n",
    "        reward = 0.0\n",
    "        for _ in range(TEST_EPISODES):\n",
    "            reward += agent.play_episode(test_env)\n",
    "        reward /=  TEST_EPISODES\n",
    "        if (reward > best_reward):\n",
    "            best_reward = reward\n",
    "            print(f\"Best reward updated: {best_reward}\")\n",
    "            print(f\"V(S) = {agent.values}\")\n",
    "        \n",
    "        if (best_reward > 0.9):\n",
    "            print(\"WON!\")\n",
    "            print(f\"Solved in {iter_no} iterations\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_notebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
